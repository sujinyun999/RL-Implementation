{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gymnasium.farama.org/environments/classic_control/cart_pole/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tutorials.pytorch.kr/intermediate/dist_tuto.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import torch.multiprocessing as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_train_processes = 3\n",
    "learning_rate = 0.0002\n",
    "update_interval = 5\n",
    "gamma = 0.98\n",
    "max_train_ep = 300\n",
    "max_test_ep = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 256)\n",
    "        self.fc_pi = nn.Linear(256, 2)\n",
    "        self.fc_v = nn.Linear(256, 1)\n",
    "\n",
    "    def pi(self, x, softmax_dim=0):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc_pi(x)\n",
    "        prob = F.softmax(x, dim=softmax_dim)\n",
    "        return prob\n",
    "\n",
    "    def v(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        v = self.fc_v(x)\n",
    "        return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(global_model, rank):\n",
    "    local_model = ActorCritic()\n",
    "    local_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "    optimizer = optim.Adam(global_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    env = gym.make('CartPole-v1')\n",
    "\n",
    "    for n_epi in range(max_train_ep):\n",
    "        done = False\n",
    "        s = env.reset()\n",
    "        while not done:\n",
    "            s_lst, a_lst, r_lst = [], [], []\n",
    "            for t in range(update_interval):\n",
    "                prob = local_model.pi(torch.from_numpy(s).float())\n",
    "                m = Categorical(prob)\n",
    "                a = m.sample().item()\n",
    "                s_prime, r, done, info = env.step(a)\n",
    "\n",
    "                s_lst.append(s)\n",
    "                a_lst.append([a])\n",
    "                r_lst.append(r/100.0)\n",
    "\n",
    "                s = s_prime\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            s_final = torch.tensor(s_prime, dtype=torch.float)\n",
    "            R = 0.0 if done else local_model.v(s_final).item()\n",
    "            td_target_lst = []\n",
    "            for reward in r_lst[::-1]:\n",
    "                R = gamma * R + reward\n",
    "                td_target_lst.append([R])\n",
    "            td_target_lst.reverse()\n",
    "\n",
    "            s_batch, a_batch, td_target = torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
    "                torch.tensor(td_target_lst)\n",
    "            advantage = td_target - local_model.v(s_batch)\n",
    "\n",
    "            pi = local_model.pi(s_batch, softmax_dim=1)\n",
    "            pi_a = pi.gather(1, a_batch)\n",
    "            loss = -torch.log(pi_a) * advantage.detach() + \\\n",
    "                F.smooth_l1_loss(local_model.v(s_batch), td_target.detach())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            for global_param, local_param in zip(global_model.parameters(), local_model.parameters()):\n",
    "                global_param._grad = local_param.grad\n",
    "            optimizer.step()\n",
    "            local_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "    env.close()\n",
    "    print(\"Training process {} reached maximum episode.\".format(rank))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(global_model):\n",
    "    env = gym.make('CartPole-v1')\n",
    "    score = 0.0\n",
    "    print_interval = 20\n",
    "\n",
    "    for n_epi in range(max_test_ep):\n",
    "        done = False\n",
    "        s = env.reset()\n",
    "        while not done:\n",
    "            prob = global_model.pi(torch.from_numpy(s).float())\n",
    "            a = Categorical(prob).sample().item()\n",
    "            s_prime, r, done, info = env.step(a)\n",
    "            s = s_prime\n",
    "            score += r\n",
    "\n",
    "        if n_epi % print_interval == 0 and n_epi != 0:\n",
    "            print(\"# of episode :{}, avg score : {:.1f}\".format(\n",
    "                n_epi, score/print_interval))\n",
    "            score = 0.0\n",
    "            time.sleep(1)\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCritic(\n",
       "  (fc1): Linear(in_features=4, out_features=256, bias=True)\n",
       "  (fc_pi): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc_v): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model = ActorCritic()\n",
    "global_model.share_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sujin/anaconda3/envs/gym101/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sujin/anaconda3/envs/gym101/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_80614/150903803.py\", line 10, in test\n",
      "    prob = global_model.pi(torch.from_numpy(s).float())\n",
      "TypeError: expected np.ndarray (got tuple)\n",
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sujin/anaconda3/envs/gym101/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sujin/anaconda3/envs/gym101/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_80614/1155698822.py\", line 15, in train\n",
      "    prob = local_model.pi(torch.from_numpy(s).float())\n",
      "TypeError: expected np.ndarray (got tuple)\n",
      "Process Process-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sujin/anaconda3/envs/gym101/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sujin/anaconda3/envs/gym101/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_80614/1155698822.py\", line 15, in train\n",
      "    prob = local_model.pi(torch.from_numpy(s).float())\n",
      "TypeError: expected np.ndarray (got tuple)\n",
      "Process Process-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sujin/anaconda3/envs/gym101/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sujin/anaconda3/envs/gym101/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_80614/1155698822.py\", line 15, in train\n",
      "    prob = local_model.pi(torch.from_numpy(s).float())\n",
      "TypeError: expected np.ndarray (got tuple)\n"
     ]
    }
   ],
   "source": [
    "processes = []\n",
    "for rank in range(n_train_processes + 1):  # + 1 for test process\n",
    "    if rank == 0:\n",
    "        p = mp.Process(target=test, args=(global_model,))\n",
    "    else:\n",
    "        p = mp.Process(target=train, args=(global_model, rank,))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym101",
   "language": "python",
   "name": "gym101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
